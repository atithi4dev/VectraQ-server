# ⚡ VectraQ-server

**VectraQ** is an upcoming intelligent document-based Q&A system that leverages Large Language Models (LLMs) and vector databases to enable users to upload PDF files and interact with them using natural language queries.

This repository serves as the **monorepo** for both the frontend and backend of the project.


---

## 🎯 Project Goals

- Upload and parse PDF files
- Chunk and embed content using LangChain + OpenAI
- Store embeddings in a vector database (ChromaDB)
- Allow users to ask questions about uploaded documents
- Generate context-aware answers using OpenAI's Chat API
- Display interactive Q&A on a clean, responsive frontend

---

## 🛠️ Tech Stack (Planned)

| Layer      | Tech                       |
|------------|----------------------------|
| Frontend   | React, Vite, Tailwind CSS  |
| Backend    | Node.js, Express.js        |
| NLP        | LangChain, OpenAI API      |
| Vector DB  | ChromaDB                   |
| Others     | Multer, pdf-parse, Axios   |

---

## 📌 Status

> 🔧 Project setup in progress. Core architecture and folder structure are being established.

---

## 📄 License

MIT License. Feel free to fork and contribute once development begins.

---

## 🤝 Contributions

Contributions will be welcome once the core pipeline is scaffolded. Stay tuned!

---

> Built with ambition — **VectraQ** aims to turn documents into dialogue.
